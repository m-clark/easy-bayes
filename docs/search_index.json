[
["index.html", "Easy Bayes with rstanarm and brms", " Easy Bayes with rstanarm and brms Michael Clark m-clark.github.io 2018-11-15 "],
["introduction.html", "Introduction ", " Introduction "],
["overview.html", "Overview", " Overview This workshop provides an overview of the rstanarm and brms packages. Basic modeling syntax is provided, as well as diagnostic checking, model comparison, and how to get more from the models. Goals Note that it is not a goal of this workshop to teach Bayesian data analysis. However, by the end of the workshop, you should be well aware of what rstanarm and brms have to offer, and how to use them, as well as what steps you might take to get the most from your models. Prerequisites You should know how to do some standard regression modeling in R. While prior exposure to Bayesian analysis is in some sense a prerequisite, this can also be seen a stepping stone to Bayesian analysis. Once you see how easy it is to get more from standard models, and how easy it is to run more complicated models, youâ€™ll likely want to use these tools even if you havenâ€™t used the Bayesian approach before. Note the following color coding used in this document: emphasis package function object/class link "],
["basic-bayesian-analysis.html", "Basic Bayesian Analysis", " Basic Bayesian Analysis The classic formula (\\(\\theta\\) = parameters): \\[p(\\theta|\\mathcal{Data}) = \\frac{p(\\mathcal{Data}|\\theta)p(\\theta)}{p(\\mathcal{Data})}\\] Conceptually, we can think about it in different ways \\[\\mathrm{posterior} \\propto likelihood * prior\\] Standard methods you are already familiar with begin and end with likelihood They can be seen as Bayesian analysis with uninformative priors Alternatively, we can think also in terms of the posterior as the combination hypothesis, and evidence, in the form of data. \\[p(hypothesis|data) \\propto p(data|hypothesis)p(hypothesis)\\] \\[\\text{updated belief} = \\text{current evidence} * \\text{prior belief or evidence}\\] Some key distinctions: Focus on distributions and uncertainty estimation instead of point estimates More natural interpretation of results Easy model criticism http://micl.shinyapps.io/prior2post/ "],
["advantages.html", "Advantages", " Advantages Incorporation of prior information Many ways to explore the model easily Tools that can handle complex models without having to change the general approach Ability to handle small samples with appropriate guard against overfitting A more intuitive inferential framework Youâ€™ll never have so much fun finding out why your model sucks! "],
["stan-and-the-stan-ecosystem.html", "Stan and the Stan ecosystem", " Stan and the Stan ecosystem "],
["stan.html", "Stan", " Stan Probabilistic programming language HMC/NUTS Compared to others: Fast convergence No conjugacy required warm-up vs. burn-in1 less autocorrelation faster for more complex models Why use? Fit very complex models Better approaches for model diagnostics Natural interval estimates for any statistic that comes out of a model data { // Data block int&lt;lower=1&gt; N; // Sample size int&lt;lower=1&gt; K; // Dimension of model matrix matrix[N, K] X; // Model Matrix vector[N] y; // Target variable } parameters { // Parameters block vector[K] beta; // Coefficient vector real&lt;lower=0&gt; sigma; // Error scale } model { // Model block vector[N] mu; mu = X * beta; // Creation of linear predictor // priors beta ~ normal(0, 10); sigma ~ cauchy(0, 5); // likelihood y ~ normal(mu, sigma); } Gelman et al. (2013) : In the simulation literature (including earlier editions of this book), the warm-up period is called burn-in, a term we now avoid because we feel it draws a misleading analogy to industrial processes in which products are stressed in order to reveal defects. We prefer the term â€˜warm-upâ€™ to describe the early phase of the simulations in which the sequences get closer to the mass of the distribution. (see also, this discussion at Gelmanâ€™s blog)â†© "],
["rstan.html", "rstan", " rstan Allows one to use Stan within R Model can be: a character string separate file with model expressed in the Stan language RStudio support for Stan (e.g. syntax highlighting) rstan runs the model, and provides a lot of other tools to assess results = stan(model_code = my_model, data = my_data_list) We will not cover this package "],
["rstanarm.html", "rstanarm", " rstanarm Developed by Stan team Good for basic to intermediate, and even somewhat complex models Pre-compiled Stan code Standard models run very quickly Without compilation will always be faster than brms for identical models "],
["brms.html", "brms", " brms Developed along with Stan team (though by one person) Good for basic to complex models Not pre-compiled Some simpler models with not much data would take longer for compilation than to actually run Extremely rapid feature integration "],
["more-stan.html", "More Stan", " More Stan Many packages to explore the results of a Stan model shinystan tidybayes various model-specific packages etc. "],
["getting-started-with-rstanarm.html", "Getting Started with rstanarm", " Getting Started with rstanarm rstan installation required. Installed as any other R package "],
["basic-glm.html", "Basic GLM", " Basic GLM School administrators study the attendance behavior of high school juniors at two schools Target: Number of days of absence Predictors: Type of program in which the student is enrolled: General, Vocational, Academic Standardized test in math Gender "],
["traditional-glm.html", "Traditional GLM", " Traditional GLM library(tidyverse) attendance = haven::read_dta(&quot;https://stats.idre.ucla.edu/stat/stata/dae/nb_data.dta&quot;) attendance &lt;- attendance %&gt;% mutate( prog = factor(prog, levels = 1:3, labels = c(&quot;General&quot;, &quot;Academic&quot;, &quot;Vocational&quot;)), prog = fct_relevel(prog, c(&#39;Vocational&#39;, &#39;General&#39;, &#39;Academic&#39;)), gender = factor(gender, labels = c(&#39;Female&#39;, &#39;Male&#39;)), id = factor(id) ) Weâ€™ll use Poisson regression2 to model the count of the number of days absent attendance_glm &lt;- glm(daysabs ~ math + gender + prog, data = attendance, family = poisson) ## summary(attendance_glm) term estimate std.error statistic p.value (Intercept) 1.489 0.081 18.302 0 math -0.007 0.001 -7.437 0 genderMale -0.242 0.047 -5.184 0 progGeneral 1.271 0.078 16.309 0 progAcademic 0.845 0.068 12.450 0 If not familiar with Poisson regression, we are modeling the log counts as a function of the covariates. Often the exponentiated coefficients are reported. For example, exp(coef(attendance_glm)['genderMale']) is 0.785. Subtracting 1 tells us there is a -21.5% decrease in the incident rate of days absent as we switch from female to male.â†© "],
["rstanarm-glm.html", "rstanarm: GLM", " rstanarm: GLM rstanarm uses the same nomenclature and general approach as base R library(rstanarm) attendance_bglm &lt;- stan_glm(daysabs ~ math + gender + prog, data = attendance, family = poisson) summary(attendance_bglm, digits = 2, prob=c(.025, .5, .975)) Model Info: function: stan_glm family: poisson [log] formula: daysabs ~ math + gender + prog algorithm: sampling priors: see help(&#39;prior_summary&#39;) sample: 4000 (posterior sample size) observations: 314 predictors: 5 Estimates: mean sd 50% 2.5% 97.5% (Intercept) 1.49 0.08 1.49 1.33 1.65 math -0.01 0.00 -0.01 -0.01 -0.01 genderMale -0.24 0.05 -0.24 -0.33 -0.15 progGeneral 1.27 0.08 1.27 1.12 1.42 progAcademic 0.84 0.07 0.84 0.71 0.98 mean_PPD 5.95 0.20 5.96 5.57 6.33 log-posterior -1324.70 1.57 -1324.39 -1328.55 -1322.59 Diagnostics: mcse Rhat n_eff (Intercept) 0.00 1.00 1862 math 0.00 1.00 3255 genderMale 0.00 1.00 3474 progGeneral 0.00 1.00 1845 progAcademic 0.00 1.00 1758 mean_PPD 0.00 1.00 3914 log-posterior 0.04 1.00 1994 For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). Summary Info: This is the same as you see in every other regression model: mean: the point estimate for the parameter sd: standard error for the point estimate quantiles: are whatever you want, but here represent the median and 95% uncertainty inteval Additional: mean_PPD: mean of the posterior predictive distribution (hopefully on par with the mean of the target variable (daysabs)) log-posterior: similar to the log-likelihood from maximum likelihood, but for the Bayesian case Diagnostics for quick eyeball inspection: Monte Carlo Standard Error: The standard error of the mean of the posterior draws. Want mcse than 10% of the posterior standard deviation. \\(n_{eff}\\): is an estimate of the effective number of independent draws from the posterior distribution of the estimand of interest. Because the draws within a chain are not independent if there is autocorrelation, the effective sample size will be smaller than the total number of iterations. Should be greater than 10% of max. \\(\\hat{R}\\): measures the ratio of the average variance of samples within each chain to the variance of the pooled samples across chains; if all chains are at equilibrium, these will be the same and RÌ‚ will be one. Desire less than 1.1. Adding more options Typical configuration would involve setting priors, as well as MCMC options such as iterations, warm-up, etc. attendance_bglm &lt;- stan_glm(daysabs ~ math + gender + prog, data = attendance, family = poisson, prior = student_t(df = 7), prior_intercept = student_t(df = 7), iter = 5000, warmup = 2000, thin = 10, cores = 4, seed = 1234) "],
["rstanarm-mixed-model.html", "rstanarm: Mixed Model", " rstanarm: Mixed Model Letâ€™s look at a mixed model for another demonstration library(lme4) sleepstudy_lmer &lt;- lmer(Reaction ~ Days + (1 + Days|Subject), data = sleepstudy) summary(sleepstudy_lmer) Linear mixed model fit by REML [&#39;lmerMod&#39;] Formula: Reaction ~ Days + (1 + Days | Subject) Data: sleepstudy REML criterion at convergence: 1743.6 Scaled residuals: Min 1Q Median 3Q Max -3.9536 -0.4634 0.0231 0.4634 5.1793 Random effects: Groups Name Variance Std.Dev. Corr Subject (Intercept) 612.09 24.740 Days 35.07 5.922 0.07 Residual 654.94 25.592 Number of obs: 180, groups: Subject, 18 Fixed effects: Estimate Std. Error t value (Intercept) 251.405 6.825 36.838 Days 10.467 1.546 6.771 Correlation of Fixed Effects: (Intr) Days -0.138 Again, rstanarm sticks with the same style sleepstudy_blmer &lt;- stan_lmer(Reaction ~ Days + (1 + Days|Subject), data = sleepstudy) summary(sleepstudy_blmer) stan_lmer family: gaussian [identity] formula: Reaction ~ Days + (1 + Days | Subject) observations: 180 ------ Median MAD_SD (Intercept) 251.616 6.503 Days 10.451 1.629 sigma 25.853 1.541 Error terms: Groups Name Std.Dev. Corr Subject (Intercept) 24.258 Days 6.901 0.08 Residual 25.959 Num. levels: Subject 18 Sample avg. posterior predictive distribution of y: Median MAD_SD mean_PPD 298.572 2.716 ------ For info on the priors used see help(&#39;prior_summary.stanreg&#39;). In the Bayesian model, the random effects are not BLUPS, but are parameters estimates in the model. data_frame(lme4 = ranef(sleepstudy_lmer)[[1]][[&#39;(Intercept)&#39;]], bayesian = ranef(sleepstudy_blmer)[[1]][[&#39;(Intercept)&#39;]]) "],
["rstanarm-other-models.html", "rstanarm: Other Models", " rstanarm: Other Models ANOVA Beta regression Conditional logistic GLM including negative binomial models Generalized additive models Nonlinear and Generalized mixed models â€˜Jointâ€™ models for longitudinal and time-to-event (e.g. survival) Multivariate Ordinal models "],
["priors.html", "Priors ", " Priors "],
["default-priors.html", "Default priors", " Default priors Depends on the model For most models: intercepts are treated differently regression coefficients have mean zero with some specific variance scale parameters (e.g. residual variance) will have appropriate priors Basically, rstanarm is going to be okay for you to use defaults If you want to change, there are plenty of resources about priors: ?prior_summary ?priors http://mc-stan.org/rstanarm/articles/priors.html https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations "],
["getting-priors.html", "Getting priors", " Getting priors prior_summary(attendance_bglm) Priors for model &#39;attendance_bglm&#39; ------ Intercept (after predictors centered) ~ normal(location = 0, scale = 10) Coefficients ~ normal(location = [0,0,0,...], scale = [2.5,2.5,2.5,...]) **adjusted scale = [0.099,2.500,2.500,...] ------ See help(&#39;prior_summary.stanreg&#39;) for more details "],
["setting-priors.html", "Setting priors", " Setting priors One can set priors with the appropriate arguments to the model function Argument Used in Applies to prior_intercept All modeling functions except stan_polr and stan_nlmer Model intercept, after centering predictors. prior All modeling functions Regression coefficients. Does not include coefficients that vary by group in a multilevel model (see prior_covariance). prior_aux stan_glm*, stan_glmer*, stan_gamm4, stan_nlmer Auxiliary parameter, e.g. error SD (interpretation depends on the GLM). prior_covariance stan_glmer*, stan_gamm4, stan_nlmer Covariance matrices in multilevel models with varying slopes and intercepts. See the stan_glmer vignette for details on this prior. The stan_polr, stan_betareg, and stan_gamm4 functions also provide additional arguments specific only to those models: Argument Used only in Applies to prior_smooth stan_gamm4 Prior for hyper-parameters in GAMs (lower values yield less flexible smooth functions). prior_counts stan_polr Prior counts of an ordinal outcome (when predictors at sample means). prior_z stan_betareg Coefficients in the model for phi. prior_intercept_z stan_betareg Intercept in the model for phi. prior_phi stan_betareg phi, if not modeled as function of predictors. Example attendance_bglm &lt;- stan_glm(daysabs ~ math + gender + prog, data = attendance, family = poisson, prior = student_t(df = 7)) "],
["installing-brms.html", "Installing brms", " Installing brms rstan installation required Installed as any other R package "],
["comparison-to-rstanarm.html", "Comparison to rstanarm", " Comparison to rstanarm brms offers more modeling capabilities, flexibility with priors, and more3 This table is from the current vignette but dated. For example, brms does impute missing values in multiple ways even.â†© "],
["models.html", "Models", " Models "],
["methods-for-brmsfit-objects.html", "Methods for brmsfit objects", " Methods for brmsfit objects This is all the fun stuff to play with after running a model methods(class = &#39;brmsfit&#39;) [1] add_ic as.array as.data.frame as.matrix [5] as.mcmc autocor bayes_factor bayes_R2 [9] bridge_sampler coef control_params expose_functions [13] family fitted fixef formula [17] getCall hypothesis kfold launch_shinystan [21] log_lik log_posterior logLik loo_linpred [25] loo_model_weights loo_predict loo_predictive_interval loo_R2 [29] loo LOO marginal_effects marginal_smooths [33] model_weights model.frame neff_ratio ngrps [37] nobs nsamples nuts_params pairs [41] parnames plot post_prob posterior_average [45] posterior_interval posterior_linpred posterior_predict posterior_samples [49] posterior_summary pp_average pp_check pp_mixture [53] predict predictive_error print prior_samples [57] prior_summary ranef residuals rhat [61] stancode standata stanplot summary [65] tidy update VarCorr vcov [69] waic WAIC see &#39;?methods&#39; for accessing help and source code "],
["models-in-brms.html", "Models in brms", " Models in brms The modeling syntax with brms mimics base R and some of the more popular packages: base R lme4 mgcv survival "],
["brms-mixed-model.html", "brms: Mixed Model", " brms: Mixed Model Weâ€™ll start with the mixed model from before Like rstanarm, brms follows lme4â€™s syntax sleepstudy_brms &lt;- brm(Reaction ~ Days + (1 + Days|Subject), data = sleepstudy) summary(sleepstudy_brms) Family: gaussian Links: mu = identity; sigma = identity Formula: Reaction ~ Days + (1 + Days | Subject) Data: sleepstudy (Number of observations: 180) Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; total post-warmup samples = 4000 Group-Level Effects: ~Subject (Number of levels: 18) Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat sd(Intercept) 26.74 7.04 15.36 43.05 1635 1.00 sd(Days) 6.52 1.50 4.20 9.95 1290 1.01 cor(Intercept,Days) 0.10 0.29 -0.46 0.67 877 1.01 Population-Level Effects: Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat Intercept 251.42 7.39 236.86 266.19 1650 1.00 Days 10.41 1.67 7.24 13.82 1233 1.00 Family Specific Parameters: Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat sigma 25.89 1.55 23.10 29.06 3200 1.00 Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat = 1). "],
["brms-mixed-model-extensions.html", "brms: Mixed Model Extensions", " brms: Mixed Model Extensions Just with mixed models, we already start to see what brms brings to the table additional distributions: ordinal, zero-inflated, beta and many more Correlated residuals, Additive mixed models, non-linear with known form, heterogeneous variance components, correlated random effects across multivariate outcomes, and more # auto regressive residual structure model &lt;- brm(Reaction ~ Days + (1 + Days|Subject), data = sleepstudy, correlation = cor_ar(~Days)) # multi-membership models model &lt;- brm(DV ~ x + (1|mm(group_1, group_2)), data = sleepstudy, correlation = cor_ar(~Days)) # smooth terms model &lt;- brm(Reaction ~ s(Days) + (1 + Days|Subject), data = sleepstudy) # use gaussian process instead model &lt;- brm(Reaction ~ gp(Days) + (1 + Days|Subject), data = sleepstudy) # multivarate outcome; q is an arbitrarily named identifier connecting random # effects. f1 = bf(DV_1 ~ x + 1|q|group) f2 = bf(DV_2 ~ x + 1|q|group) f = f1 + f2 model &lt;- brm(f, data = mydata) "],
["brms-mo-models-mo-models-mo-models.html", "brms: Moâ€™ models, moâ€™ models, moâ€™ models!", " brms: Moâ€™ models, moâ€™ models, moâ€™ models! GAM Distributional response (e.g. model the variance as well as the mean) Gaussian Processes ZIP Multivariate Missing data imputation from a Bayesian approach Measurement error # additional distributions model = brm(y ~ x + z, family = skew_normal, student, shifted_lognormal, weibull, frechet, gen_extreme_value, exgaussian, wiener, Beta, von_mises, asym_laplace, hurdle_poisson,_negbinomial,_gamma,_lognormal, zero_inflated_poisson,_negbinomial,_beta,_binomial; zero_one_inflated_beta, categorical, ordinal: cumulative, sratio, cratio, acat) # model the variance as well as the mean fit1 &lt;- brm(bf(y ~ x + z, sigma ~ x), data = dat1, family = gaussian) # missing values bform &lt;- bf(bmi | mi() ~ age * mi(chl)) + bf(chl | mi() ~ age) + set_rescor(FALSE) fit &lt;- brm(bform, data = nhanes) # non-linear model with known form nlform &lt;- bf(cum ~ ult * (1 - exp(-(dev / theta)^omega)), ult ~ 1 + (1 | AY), omega ~ 1, theta ~ 1, nl = TRUE) # measurement error fit1 &lt;- brm(y ~ me(x1, sdx) + me(x2, sdx), data = dat, save_mevars = TRUE) "],
["model-criticism-in-rstanarm-and-brms.html", "Model Criticism in rstanarm and brms", " Model Criticism in rstanarm and brms Much of the core functionality is the same across both packages Functions that exist in both are identical We will focus on brms, which has some extras "],
["model-exploration.html", "Model Exploration ", " Model Exploration "],
["linear-models.html", "Linear models", " Linear models Get a simple coefficient plot4 stanplot(attendance_brms, pars = c(&#39;math&#39;, &#39;gender&#39;, &#39;prog&#39;)) For linear models, one might be interested in some notion of \\(R^2\\) Automatically get an interval estimate as well fit &lt;- brm(mpg ~ wt + cyl, data = mtcars, refresh = 0) bayes_R2(fit, digits=2) Estimate Est.Error Q2.5 Q97.5 R2 0.8178259 0.03046187 0.7357123 0.8527994 Mixed models can include random effects or not bayes_R2(sleepstudy_brms, re_formula = NA) # not included Estimate Est.Error Q2.5 Q97.5 R2 0.2815599 0.06296109 0.1561139 0.4018669 bayes_R2(sleepstudy_brms) # included Estimate Est.Error Q2.5 Q97.5 R2 0.7908612 0.01784671 0.7497048 0.8206132 I prefer my own package visibly for this. There are a couple other plotting functions for some of the common brms models (e.g. glm, mixed)â†© "],
["marginal-effects.html", "Marginal effects", " Marginal effects brms allows one to plot marginal effects For standard linear models this is useful for group comparisons and interactions For nonlinear models (glm and beyond) useful for any effect marginal_effects(attendance_brms) These are ggplot objects, so you can modify them accordingly math_me = marginal_effects(attendance_brms, effects = &#39;math&#39;) plot(math_me, plot = F, rug = T, rug_args = list(color=&#39;darkred&#39;), points = T, point_args = list(color=&#39;papayawhip&#39;))[[1]] + theme_black() Example with smooth interaction attendance_brms_inter = update(attendance_brms, ~ . - math + s(math, by=gender), cores=4) marginal_smooths(attendance_brms_inter) "],
["hypothesis-tests.html", "Hypothesis tests", " Hypothesis tests Null hypothesis testing doesnâ€™t apply to the Bayesian context (thankfully) However, we can still ask questions about the probability of certain outcomes attendance_brms Family: poisson Links: mu = log Formula: daysabs ~ math + gender + prog Data: attendance (Number of observations: 314) Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 10; total post-warmup samples = 400 Population-Level Effects: Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat Intercept 1.49 0.08 1.32 1.63 376 1.00 math -0.01 0.00 -0.01 -0.01 401 1.00 genderMale -0.25 0.04 -0.34 -0.16 421 0.99 progGeneral 1.27 0.08 1.11 1.43 391 1.00 progAcademic 0.85 0.07 0.70 0.99 404 1.00 Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat = 1). hypothesis(attendance_brms, &#39;genderMale &lt; -.2&#39;) Hypothesis Tests for class b: Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star 1 (genderMale)-(-.2) &lt; 0 -0.05 0.04 -Inf 0.03 5.9 0.86 --- &#39;*&#39;: The expected value under the hypothesis lies outside the 95%-CI. Posterior probabilities of point hypotheses assume equal prior probabilities. hypothesis(attendance_brms, &#39;progGeneral/progAcademic &gt; 1&#39;) Hypothesis Tests for class b: Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star 1 (progGeneral/prog... &gt; 0 0.51 0.09 0.37 Inf Inf 1 * --- &#39;*&#39;: The expected value under the hypothesis lies outside the 95%-CI. Posterior probabilities of point hypotheses assume equal prior probabilities. "],
["extracting-results.html", "Extracting results", " Extracting results It is easy to get access to the output Example: grab draws from the posterior for math posterior_samples(attendance_brms, pars = &#39;math&#39;) %&gt;% head() b_math 1 -0.005945358 2 -0.006030774 3 -0.009060251 4 -0.007864525 5 -0.006196730 6 -0.006510296 posterior_samples(attendance_brms, pars = &#39;math&#39;) %&gt;% qplot(data=., x = b_math, geom = &#39;density&#39;) Tidy methods for data extraction The broom package can make your model results easier to work with5 library(broom) tidy(attendance_brms) term estimate std.error lower upper 1 b_Intercept 1.486260e+00 0.0807602243 1.353464e+00 1.613702e+00 2 b_math -6.947692e-03 0.0009433085 -8.589656e-03 -5.444662e-03 3 b_genderMale -2.450094e-01 0.0444296384 -3.257716e-01 -1.680750e-01 4 b_progGeneral 1.273018e+00 0.0809187810 1.148042e+00 1.398220e+00 5 b_progAcademic 8.458137e-01 0.0716282175 7.205499e-01 9.549422e-01 6 lp__ -1.320972e+03 1.6287393824 -1.324051e+03 -1.319034e+03 library(kableExtra) tidy(attendance_brms) %&gt;% filter(grepl(term, pattern = &#39;^b&#39;)) %&gt;% mutate(term = c(&#39;Intercept&#39;, &#39;Math&#39;, &#39;Male&#39;, &#39;General&#39;, &#39;Academic&#39;)) %&gt;% rename_all(str_to_title) %&gt;% kable(digits = 2) Term Estimate Std.error Lower Upper Intercept 1.49 0.08 1.35 1.61 Math -0.01 0.00 -0.01 -0.01 Male -0.25 0.04 -0.33 -0.17 General 1.27 0.08 1.15 1.40 Academic 0.85 0.07 0.72 0.95 tidybayes Bayesian analysis + tidy data + geoms # add fitted values given the posterior draws for model parameters library(tidybayes) attendance %&gt;% add_fitted_draws(attendance_brms) # A tibble: 125,600 x 10 # Groups: id, gender, math, daysabs, prog, .row [314] id gender math daysabs prog .row .chain .iteration .draw .value &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; 1 1001 Male 63 4 Academic 1 NA NA 1 5.05 2 1001 Male 63 4 Academic 1 NA NA 2 5.52 3 1001 Male 63 4 Academic 1 NA NA 3 4.83 4 1001 Male 63 4 Academic 1 NA NA 4 4.97 5 1001 Male 63 4 Academic 1 NA NA 5 5.41 6 1001 Male 63 4 Academic 1 NA NA 6 4.98 7 1001 Male 63 4 Academic 1 NA NA 7 5.37 8 1001 Male 63 4 Academic 1 NA NA 8 5.30 9 1001 Male 63 4 Academic 1 NA NA 9 4.99 10 1001 Male 63 4 Academic 1 NA NA 10 5.20 # ... with 125,590 more rows sleepstudy %&gt;% modelr::data_grid(Days = Days, Subject = levels(Subject)) %&gt;% add_predicted_draws(sleepstudy_brms) %&gt;% ggplot(aes(x = Days)) + stat_lineribbon(aes(y = .prediction), color = NineteenEightyR::electronic_night()[1], .width = seq(.5, .99, by = .01), alpha = .5, show.legend = F) + geom_point(aes(y = Reaction), data = sleepstudy, alpha=.25) + scico::scale_fill_scico_d(alpha=.1, palette = &#39;acton&#39;, direction = -1) Questions about tidybayes may be shouted across the street ðŸ˜€ Developed by Matthew Kay Assistant Professor at UMSI The posterior predictive distribution is the distribution of the outcome variable implied by a model after using the observed data y (a vector of outcome values), and typically predictors X, to update our beliefs about the unknown parameters Î¸ in the model. For each draw of the parameters Î¸ from the posterior distribution p(Î¸ | y, X) we generate an entire vector of outcomes.â†© "],
["model-diagnostics.html", "Model Diagnostics", " Model Diagnostics Numerous model diagnostics are available to the Bayesian analyst The Stan ecosystem makes exploring these not only easy, but fun! "],
["shinystan.html", "shinystan", " shinystan A basic trace/density plot (boring) plot(attendance_brms) shinystan allows for interactive exploration of model diagnostics Just use launch_shinystan on any model object from rstan, rstanarm, or brms launch_shinystan(attendance_brms) "],
["posterior-predictive-checks.html", "Posterior Predictive Checks", " Posterior Predictive Checks Posterior predictive checks can let us inspect what the model suggests for our target variable vs. what actually is the case[^ppcheck] pp_check(attendance_brms) Lots to play with pp_check(attendance_brms, type=&#39;x&#39;) Error: Type &#39;x&#39; is not a valid ppc type. Valid types are: &#39;bars&#39;, &#39;bars_grouped&#39;, &#39;boxplot&#39;, &#39;data&#39;, &#39;dens&#39;, &#39;dens_overlay&#39;, &#39;ecdf_overlay&#39;, &#39;error_binned&#39;, &#39;error_hist&#39;, &#39;error_hist_grouped&#39;, &#39;error_scatter&#39;, &#39;error_scatter_avg&#39;, &#39;error_scatter_avg_vs_x&#39;, &#39;freqpoly&#39;, &#39;freqpoly_grouped&#39;, &#39;hist&#39;, &#39;intervals&#39;, &#39;intervals_data&#39;, &#39;intervals_grouped&#39;, &#39;loo_intervals&#39;, &#39;loo_pit&#39;, &#39;loo_pit_overlay&#39;, &#39;loo_pit_qq&#39;, &#39;loo_ribbon&#39;, &#39;ribbon&#39;, &#39;ribbon_data&#39;, &#39;ribbon_grouped&#39;, &#39;rootogram&#39;, &#39;scatter&#39;, &#39;scatter_avg&#39;, &#39;scatter_avg_grouped&#39;, &#39;stat&#39;, &#39;stat_2d&#39;, &#39;stat_freqpoly_grouped&#39;, &#39;stat_grouped&#39;, &#39;violin_grouped&#39; How well did we capture the mean, or some quantile? pp_check(attendance_brms, type=&#39;stat&#39;, stat=&#39;mean&#39;) q75 &lt;- function(y) quantile(y, 0.75) pp_check(attendance_brms, type=&#39;stat&#39;, stat=&#39;q75&#39;, nsamples = 100) What can we say about the predictive error? pp_check(attendance_brms, type=&#39;error_scatter_avg&#39;) pp_check(attendance_brms, type=&#39;intervals&#39;) pp_check(attendance_brms, x = &#39;math&#39;, type=&#39;error_scatter_avg_vs_x&#39;) The Poissonâ€™s underlying assumption of the mean equaling the variance rarely holds with typical data. One way to handle overdispersion in count models is to move to something like negative binomial or other approaches. Interestingly, for Poisson models we can have a random effect per observation6 to model additional variance. In this case, our pp_check suggests a much better result. attendance_brms_add_re = update(attendance_brms, . ~ . + (1|id), newdata = attendance) pp_check(attendance_brms_add_re) For more on this see Ben Bolkerâ€™s demonstration with lme4. This essentially changes the model to incorporate a Poisson log-normal distribution. As Montesinos-LÃ³pez et al. (2017) describe: &gt; The Poisson component of the Poisson-lognormal distribution accommodates integer inputs (or outputs) to describe the actual number of counts observed within a single unit or sample, while the lognormal component of the distribution describes the overdispersion in the Poisson rate parameterâ€¦â†© "],
["observation-level.html", "Observation Level", " Observation Level We can get into observation level diagnostics as well While the process is technical, we can use the simple visualization to note â€˜outliersâ€™7 Think of it as leave-one-out (LOO) cross-validation error for a single data point Look for values above .7 (though this default can be changed) plot(loo(attendance_brms)) title(&#39;&#39;) Pareto smoothed importance sampling. See Vehtari, Gelman, and Gabry (2015) and Vehtari, Gelman, and Gabry (2017) for details.â†© "],
["model-performance.html", "Model Performance ", " Model Performance "],
["prediction.html", "Prediction", " Prediction The usual methods of fitted and predict can be used summary raw "],
["model-comparison.html", "Model Comparison", " Model Comparison Model comparison can be achieved in much the same way we do with standard models WAIC = widely applicable information criterion a Bayesian AIC (lower is better) In the Bayesian context, we would have a distribution for the WAIC also waic(attendance_brms, attendance_brms_add_re) WAIC SE attendance_brms 2669.26 146.95 attendance_brms_add_re 1419.97 26.27 attendance_brms - attendance_brms_add_re 1249.29 135.37 "],
["model-averaging.html", "Model Averaging", " Model Averaging Why choose a model? Average predictions across models via stacking ## pp_average(attendance_brms, attendance_brms_add_re) Estimate Est.Error Q2.5 Q97.5 [1,] 4.2400 2.650465 0 11.000 [2,] 4.2150 2.877407 0 10.000 [3,] 2.7900 2.181237 0 8.025 [4,] 3.4725 2.519944 0 9.000 [5,] 3.7175 2.668426 0 11.000 [6,] 11.9450 4.654690 4 23.000 "],
["summary.html", "Summary", " Summary Implementing Bayesian methods has never been easier rstanarm and brms allow one to worry about the concepts instead of syntax Bayesian analysis provides additional ways to: combat complex models diagnosis issues get creative with results Even standard/traditional/basic models become more fun! "],
["exercise.html", "Exercise", " Exercise Whether a survey respondent agrees or disagrees with a conservative statement about the role of women in society 1974/1975 Survey Women should take care of running their homes and leave running the country up to men Modeled as a function of the gender and years of education (0-20) of the respondents Data from the HSAUR3 package Observations are aggregate counts at education levels for men and women Run a binomial logistic regression modeling the proportion of those who agreed - If you are more familiar with binary logistic regression, you may â€˜unroleâ€™ this data to be disagree-agree for each individual (the analysis is the same) data(&quot;womensrole&quot;, package = &quot;HSAUR3&quot;) # alternative not requiring package womensrole = readr::read_csv(&#39;https://github.com/m-clark/easy-bayes/raw/master/data/womensrole.csv&#39;) womensrole_glm &lt;- glm(cbind(agree, disagree) ~ education + gender, data = womensrole, family = binomial) summary(womensrole_glm) Now use brms or rstanarm to run the same analysis Explore it fully by: plotting the coefficients (stanplot) use shinystan to explore diagnostics (launch_shinystan) explore the posterior predictive distribtution (pp_check) plot the marginal effect of the predictor variables (marginal_effects) my_model_bayes = ? "],
["references.html", "References", " References Stan discussion group includes forums specific to rstanarm and brms "]
]
