[
["index.html", "Easy Bayes with rstanarm and brms", " Easy Bayes with rstanarm and brms Michael Clark m-clark.github.io 2018-11-14 "],
["introduction.html", "Introduction ", " Introduction "],
["overview.html", "Overview", " Overview This workshop provides an overview of the rstanarm and brms packages. Basic modeling syntax is provided, as well as diagnostic checking, model comparison, and how to get more from the models. Goals Note that it is not a goal of this workshop to teach Bayesian data analysis. However, by the end of the workshop, you should be well aware of what rstanarm and brms have to offer, and how to use them, as well as what steps you might take to get the most from your models. Prerequisites You should know how to do some standard regression modeling in R. While prior exposure to Bayesian analysis is in some sense a prerequisite, this can also be seen a stepping stone to Bayesian analysis. Once you see how easy it is to get more from standard models, and how easy it is to run more complicated models, you’ll likely want to use these tools even if you haven’t used the Bayesian approach before. Note the following color coding used in this document: emphasis package function object/class link "],
["basic-bayesian-analysis.html", "Basic Bayesian Analysis", " Basic Bayesian Analysis The classic formula (\\(\\theta\\) = parameters): \\[p(\\theta|\\mathcal{Data}) = \\frac{p(\\mathcal{Data}|\\theta)p(\\theta)}{p(\\mathcal{Data})}\\] Conceptually, we can think about it in different ways. \\[\\mathrm{posterior} \\propto likelihood * prior\\] Standard methods you are already familiar with begin and end with likelihood. They can be seen as Bayesian analysis with uninformative priors. Alternatively, we can think also in terms of the posterior as the combination hypothesis, and evidence, in the form of data. \\[p(hypothesis|data) \\propto p(data|hypothesis)p(hypothesis)\\] $$$$ \\[\\text{updated belief} = \\text{current evidence} * \\text{prior belief or evidence}\\] Some key distinctions: Distributions and uncertainty estimation instead of point estimates However, given the distribution for a parameter, we still obtain point estimates Easy model criticism http://micl.shinyapps.io/prior2post/ "],
["advantages.html", "Advantages", " Advantages Incorporation of prior information Many ways to explore the model easily Tools that can handle complex models without having to change the general approach Ability to handle small samples with appropriate guard against overfitting A more intuitive inferential framework You’ll never have so much fun finding out why your model sucks! "],
["stan-and-the-stan-ecosystem.html", "Stan and the Stan ecosystem", " Stan and the Stan ecosystem "],
["stan.html", "Stan", " Stan Probabilistic programming language HMC/NUTS Compared to others: Fast convergence No conjugacy required warmup vs. burnin1 less autocorrelation faster for more complex models Why use? Fit very complex models Better approaches for model diagnostics Natural interval estimates for any statistic that comes out of a model data { // Data block int&lt;lower=1&gt; N; // Sample size int&lt;lower=1&gt; K; // Dimension of model matrix matrix[N, K] X; // Model Matrix vector[N] y; // Target variable } parameters { // Parameters block vector[K] beta; // Coefficient vector real&lt;lower=0&gt; sigma; // Error scale } model { // Model block vector[N] mu; mu = X * beta; // Creation of linear predictor // priors beta ~ normal(0, 10); sigma ~ cauchy(0, 5); // likelihood y ~ normal(mu, sigma); } Gelman et al. (2013) : In the simulation literature (including earlier editions of this book), the warm-up period is called burn-in, a term we now avoid because we feel it draws a misleading analogy to industrial processes in which products are stressed in order to reveal defects. We prefer the term ‘warm-up’ to describe the early phase of the simulations in which the sequences get closer to the mass of the distribution. (see also, this discussion at Gelman’s blog)↩ "],
["rstan.html", "rstan", " rstan Allows one to use Stan within R Model can be: a character string separate file with model expressed in the Stan language RStudio support for Stan (e.g. syntax highlighting) rstan runs the model, and provides a lot of other tools to assess results = stan(model_code = my_model, data = my_data_list) We will not cover this package "],
["rstanarm.html", "rstanarm", " rstanarm Developed by Stan team Good for basic to intermediate, and even somewhat complex models Precompiled stan code Standard models run very quickly Without compilation will always be faster than brms for identical models "],
["brms.html", "brms", " brms Developed along with Stan team (though by one person) Good for basic to complex models Not pre-compiled Some simpler models with not much data would take longer for compilation than to actually run Extremely rapid feature integration "],
["more-stan.html", "More Stan", " More Stan Many packages to explore the results of a Stan model shinystan tidybayes various model-specific packages etc. "],
["getting-started-with-rstanarm.html", "Getting Started with rstanarm", " Getting Started with rstanarm rstan installation required. Installed as any other R package "],
["basic-glm.html", "Basic GLM", " Basic GLM School administrators study the attendance behavior of high school juniors at two schools Target: Number of days of absence Predictors: Type of program in which the student is enrolled: General, Vocational, Academic Standardized test in math Gender "],
["traditional-glm.html", "Traditional GLM", " Traditional GLM library(tidyverse) attendance = haven::read_dta(&quot;https://stats.idre.ucla.edu/stat/stata/dae/nb_data.dta&quot;) attendance &lt;- attendance %&gt;% mutate( prog = factor(prog, levels = 1:3, labels = c(&quot;General&quot;, &quot;Academic&quot;, &quot;Vocational&quot;)), prog = fct_relevel(prog, c(&#39;Vocational&#39;, &#39;General&#39;, &#39;Academic&#39;)), gender = factor(gender, labels = c(&#39;Female&#39;, &#39;Male&#39;)), id = factor(id) ) We’ll use Poisson regression2 to model the count of the number of days absent attendance_glm &lt;- glm(daysabs ~ math + gender + prog, data = attendance, family = poisson) ## summary(attendance_glm) term estimate std.error statistic p.value (Intercept) 1.489 0.081 18.302 0 math -0.007 0.001 -7.437 0 genderMale -0.242 0.047 -5.184 0 progGeneral 1.271 0.078 16.309 0 progAcademic 0.845 0.068 12.450 0 If not familiar with Poisson regression, we are modeling the log counts as a function of the covariates. Often the exponentiated coefficients are reported. For example, exp(coef(attendance_glm)['genderMale']) is 0.785. Subtracting 1 tells us there is a -21.5% decrease in the incident rate of days absent as we switch from female to male.↩ "],
["rstanarm-glm.html", "rstanarm: GLM", " rstanarm: GLM rstanarm uses the same nomenclature and general approach as base R library(rstanarm) attendance_bglm &lt;- stan_glm(daysabs ~ math + gender + prog, data = attendance, family = poisson) summary(attendance_bglm, digits = 3) stan_glm family: poisson [log] formula: daysabs ~ math + gender + prog observations: 314 predictors: 5 ------ Median MAD_SD (Intercept) 1.488 0.083 math -0.007 0.001 genderMale -0.242 0.046 progGeneral 1.269 0.079 progAcademic 0.844 0.068 Sample avg. posterior predictive distribution of y: Median MAD_SD mean_PPD 5.955 0.198 ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg Adding more options Typical configuration would involve setting priors, as well as MCMC options such as iterations, warmup, etc. attendance_bglm &lt;- stan_glm(daysabs ~ math + gender + prog, data = attendance, family = poisson, prior = student_t(df = 7), prior_intercept = student_t(df = 7), iter = 5000, warmup = 2000, thin = 10, cores = 4, seed = 1234) "],
["rstanarm-mixed-model.html", "rstanarm: Mixed Model", " rstanarm: Mixed Model Let’s look at a mixed model for another demonstration library(lme4) sleepstudy_lmer &lt;- lmer(Reaction ~ Days + (1 + Days|Subject), data = sleepstudy) summary(sleepstudy_lmer) Linear mixed model fit by REML [&#39;lmerMod&#39;] Formula: Reaction ~ Days + (1 + Days | Subject) Data: sleepstudy REML criterion at convergence: 1743.6 Scaled residuals: Min 1Q Median 3Q Max -3.9536 -0.4634 0.0231 0.4634 5.1793 Random effects: Groups Name Variance Std.Dev. Corr Subject (Intercept) 612.09 24.740 Days 35.07 5.922 0.07 Residual 654.94 25.592 Number of obs: 180, groups: Subject, 18 Fixed effects: Estimate Std. Error t value (Intercept) 251.405 6.825 36.838 Days 10.467 1.546 6.771 Correlation of Fixed Effects: (Intr) Days -0.138 Again, rstanarm sticks with the same style sleepstudy_blmer &lt;- stan_lmer(Reaction ~ Days + (1 + Days|Subject), data = sleepstudy) summary(sleepstudy_blmer) stan_lmer family: gaussian [identity] formula: Reaction ~ Days + (1 + Days | Subject) observations: 180 ------ Median MAD_SD (Intercept) 251.616 6.503 Days 10.451 1.629 Auxiliary parameter(s): Median MAD_SD sigma 25.853 1.541 Error terms: Groups Name Std.Dev. Corr Subject (Intercept) 24.258 Days 6.901 0.08 Residual 25.959 Num. levels: Subject 18 Sample avg. posterior predictive distribution of y: Median MAD_SD mean_PPD 298.572 2.716 ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg In the Bayesian model, the random effects are not BLUPS, but are parameters estimates in the model. data_frame(lme4 = ranef(sleepstudy_lmer)[[1]][[&#39;(Intercept)&#39;]], bayesian = ranef(sleepstudy_blmer)[[1]][[&#39;(Intercept)&#39;]]) "],
["rstanarm-other-models.html", "rstanarm: Other Models", " rstanarm: Other Models ANOVA Beta regression Conditional logistic GLM including negative binomial models Generalized additive models Nonlinear and Generalized mixed models ‘Joint’ models for longitudinal and time-to-event (e.g. survival) Multivariate Ordinal models "],
["priors.html", "Priors ", " Priors "],
["default-priors.html", "Default priors", " Default priors Depends on the model For most models: intercepts are treated differently regression coefficients have mean zero with some specific variance scale parameters (e.g. residual variance) will have appropriate priors Basically, rstanarm is going to be okay for you to use defaults If you want to change, there are plenty of resources about priors: ?prior_summary ?priors http://mc-stan.org/rstanarm/articles/priors.html https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations "],
["getting-priors.html", "Getting priors", " Getting priors prior_summary(attendance_bglm) Priors for model &#39;attendance_bglm&#39; ------ Intercept (after predictors centered) ~ normal(location = 0, scale = 10) Coefficients ~ normal(location = [0,0,0,...], scale = [2.5,2.5,2.5,...]) **adjusted scale = [0.099,2.500,2.500,...] ------ See help(&#39;prior_summary.stanreg&#39;) for more details "],
["setting-priors.html", "Setting priors", " Setting priors One can set priors with the appropriate arguments to the model function Argument Used in Applies to prior_intercept All modeling functions except stan_polr and stan_nlmer Model intercept, after centering predictors. prior All modeling functions Regression coefficients. Does not include coefficients that vary by group in a multilevel model (see prior_covariance). prior_aux stan_glm*, stan_glmer*, stan_gamm4, stan_nlmer Auxiliary parameter, e.g. error SD (interpretation depends on the GLM). prior_covariance stan_glmer*, stan_gamm4, stan_nlmer Covariance matrices in multilevel models with varying slopes and intercepts. See the stan_glmer vignette for details on this prior. The stan_polr, stan_betareg, and stan_gamm4 functions also provide additional arguments specific only to those models: Argument Used only in Applies to prior_smooth stan_gamm4 Prior for hyperparameters in GAMs (lower values yield less flexible smooth functions). prior_counts stan_polr Prior counts of an ordinal outcome (when predictors at sample means). prior_z stan_betareg Coefficients in the model for phi. prior_intercept_z stan_betareg Intercept in the model for phi. prior_phi stan_betareg phi, if not modeled as function of predictors. Example attendance_bglm &lt;- stan_glm(daysabs ~ math + gender + prog, data = attendance, family = poisson, prior = student_t(df = 7)) "],
["installing-brms.html", "Installing brms", " Installing brms rstan installation required Installed as any other R package "],
["comparison-to-rstanarm.html", "Comparison to rstanarm", " Comparison to rstanarm brms offers more modeling capabilities, flexibility with priors, and more3 This table is from the current vignette but dated. For example, brms does impute missing values in multiple ways even.↩ "],
["models.html", "Models", " Models "],
["methods-for-brmsfit-objects.html", "Methods for brmsfit objects", " Methods for brmsfit objects This is all the fun stuff to play with after running a model methods(class = &#39;brmsfit&#39;) [1] add_ic as.array as.data.frame as.matrix [5] as.mcmc autocor bayes_factor bayes_R2 [9] bridge_sampler coef control_params expose_functions [13] extract_draws family fitted fixef [17] formula getCall hypothesis kfold [21] launch_shinystan log_lik log_posterior logLik [25] loo LOO loo_linpred loo_model_weights [29] loo_predict loo_predictive_interval loo_R2 marginal_effects [33] marginal_smooths model.frame model_weights neff_ratio [37] ngrps nobs nsamples nuts_params [41] pairs parnames plot post_prob [45] posterior_average posterior_interval posterior_linpred posterior_predict [49] posterior_samples posterior_summary pp_average pp_check [53] pp_mixture predict predictive_error predictive_interval [57] print prior_samples prior_summary ranef [61] residuals rhat stancode standata [65] stanplot summary tidy update [69] VarCorr vcov waic WAIC see &#39;?methods&#39; for accessing help and source code "],
["models-in-brms.html", "Models in brms", " Models in brms The modeling syntax with brms mimics base R and some of the more popular packages: base R lme4 mgcv survival "],
["brms-mixed-model.html", "brms: Mixed Model", " brms: Mixed Model We’ll start with the mixed model from before Like rstanarm, brms follows lme4’s syntax sleepstudy_brms &lt;- brm(Reaction ~ Days + (1 + Days|Subject), data = sleepstudy) summary(sleepstudy_brms) Family: gaussian Links: mu = identity; sigma = identity Formula: Reaction ~ Days + (1 + Days | Subject) Data: sleepstudy (Number of observations: 180) Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; total post-warmup samples = 4000 Group-Level Effects: ~Subject (Number of levels: 18) Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat sd(Intercept) 26.74 7.04 15.36 43.05 1635 1.00 sd(Days) 6.52 1.50 4.20 9.95 1290 1.01 cor(Intercept,Days) 0.10 0.29 -0.46 0.67 877 1.01 Population-Level Effects: Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat Intercept 251.42 7.39 236.86 266.19 1650 1.00 Days 10.41 1.67 7.24 13.82 1233 1.00 Family Specific Parameters: Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat sigma 25.89 1.55 23.10 29.06 3200 1.00 Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat = 1). "],
["brms-mixed-model-extensions.html", "brms: Mixed Model Extensions", " brms: Mixed Model Extensions Just with mixed models, we already start to see what brms brings to the table additional distributions: ordinal, zero-inflated, beta and many more Correlated residuals, Additive mixed models, non-linear with known form, heterogenous variance components, correlated random effects across multivariate outcomes, and more # auto regressive residual structure model &lt;- brm(Reaction ~ Days + (1 + Days|Subject), data = sleepstudy, correlation = cor_ar(~Days)) # multi-membership models model &lt;- brm(DV ~ x + (1|mm(group_1, group_2)), data = sleepstudy, correlation = cor_ar(~Days)) # smooth terms model &lt;- brm(Reaction ~ s(Days) + (1 + Days|Subject), data = sleepstudy) # use gaussian process instead model &lt;- brm(Reaction ~ gp(Days) + (1 + Days|Subject), data = sleepstudy) # multivarate outcome; q is an arbitrarily named identifier connecting random # effects. f1 = bf(DV_1 ~ x + 1|q|group) f2 = bf(DV_2 ~ x + 1|q|group) f = f1 + f2 model &lt;- brm(f, data = mydata) "],
["brms-mo-models-mo-models-mo-models.html", "brms: Mo’ models, mo’ models, mo’ models!", " brms: Mo’ models, mo’ models, mo’ models! GAM (gp) Distributional response (e.g. model the variance as well as the mean) Gaussian Processes ZIP Multivariate Missing data imputation from a Bayesian approach Measurement error # additional distributions model = brm(y ~ x + z, family = skew_normal, student, shifted_lognormal, weibull, frechet, gen_extreme_value, exgaussian, wiener, Beta, von_mises, asym_laplace, hurdle_poisson,_negbinomial,_gamma,_lognormal, zero_inflated_poisson,_negbinomial,_beta,_binomial; zero_one_inflated_beta, categorical, ordinal: cumulative, sratio, cratio, acat) # model the variance as well as the mean fit1 &lt;- brm(bf(y ~ x + z, sigma ~ x), data = dat1, family = gaussian) # missing values bform &lt;- bf(bmi | mi() ~ age * mi(chl)) + bf(chl | mi() ~ age) + set_rescor(FALSE) fit &lt;- brm(bform, data = nhanes) # non-linear model with known form nlform &lt;- bf(cum ~ ult * (1 - exp(-(dev / theta)^omega)), ult ~ 1 + (1 | AY), omega ~ 1, theta ~ 1, nl = TRUE) # measurement error fit1 &lt;- brm(y ~ me(x1, sdx) + me(x2, sdx), data = dat, save_mevars = TRUE) "],
["model-criticism-in-rstanarm-and-brms.html", "Model Criticism in rstanarm and brms", " Model Criticism in rstanarm and brms Much of the core functionality is the same across both packages Functions that exist in both are identical We will focus on brms, which has some extras "],
["model-exploration.html", "Model Exploration ", " Model Exploration "],
["linear-models.html", "Linear models", " Linear models Get a simple coefficient plot4 stanplot(attendance_brms) For linear models, one might be interested in some notion of \\(R^2\\) Automatically get an interval estimate as well fit &lt;- brm(mpg ~ wt + cyl, data = mtcars, refresh = 0) bayes_R2(fit, digits=2) Estimate Est.Error Q2.5 Q97.5 R2 0.8180078 0.03055521 0.7410065 0.8528425 Mixed models can include random effects or not bayes_R2(sleepstudy_brms, re_formula = NA) Estimate Est.Error Q2.5 Q97.5 R2 0.2815599 0.06296109 0.1561139 0.4018669 bayes_R2(sleepstudy_brms) Estimate Est.Error Q2.5 Q97.5 R2 0.7908612 0.01784671 0.7497048 0.8206132 I prefer my own package visibly for this. There are a couple other plotting functions for some of the common brms models (e.g. glm, mixed)↩ "],
["marginal-effects.html", "Marginal effects", " Marginal effects brms allows one to to plot marginal effects For standard linear models this is useful for group comparisons and interactions For nonlinear models (glm and beyond) useful for any effect marginal_effects(attendance_brms) "],
["hypothesis-tests.html", "Hypothesis tests", " Hypothesis tests Null hypothesis testing doesn’t apply to the Bayesian context However, we can still ask questions about the probability of certain outcomes attendance_brms Family: poisson Links: mu = log Formula: daysabs ~ math + gender + prog Data: attendance (Number of observations: 314) Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 10; total post-warmup samples = 400 Population-Level Effects: Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat Intercept 1.49 0.08 1.32 1.63 376 1.00 math -0.01 0.00 -0.01 -0.01 401 1.00 genderMale -0.25 0.04 -0.34 -0.16 421 0.99 progGeneral 1.27 0.08 1.11 1.43 391 1.00 progAcademic 0.85 0.07 0.70 0.99 404 1.00 Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat = 1). hypothesis(attendance_brms, &#39;genderMale &lt; -.2&#39;) Hypothesis Tests for class b: Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star 1 (genderMale)-(-.2) &lt; 0 -0.05 0.04 -Inf 0.03 5.9 0.86 --- &#39;*&#39;: The expected value under the hypothesis lies outside the 95%-CI. Posterior probabilities of point hypotheses assume equal prior probabilities. hypothesis(attendance_brms, &#39;progGeneral/progAcademic &gt; 1&#39;) Hypothesis Tests for class b: Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star 1 (progGeneral/prog... &gt; 0 0.51 0.09 0.37 Inf Inf 1 * --- &#39;*&#39;: The expected value under the hypothesis lies outside the 95%-CI. Posterior probabilities of point hypotheses assume equal prior probabilities. "],
["extracting-results.html", "Extracting results", " Extracting results If there is something specific you need to do with the results, it is easy to get access to the output posterior_samples(attendance_brms, pars = &#39;math&#39;) %&gt;% head() b_math 1 -0.005945358 2 -0.006030774 3 -0.009060251 4 -0.007864525 5 -0.006196730 6 -0.006510296 posterior_samples(attendance_brms, pars = &#39;math&#39;) %&gt;% qplot(data=., x = b_math, geom = &#39;density&#39;) Tidy methods for data extraction The broom package can make your model results easier to work with library(broom) tidy(attendance_brms) term estimate std.error lower upper 1 b_Intercept 1.486260e+00 0.0807602243 1.353464e+00 1.613702e+00 2 b_math -6.947692e-03 0.0009433085 -8.589656e-03 -5.444662e-03 3 b_genderMale -2.450094e-01 0.0444296384 -3.257716e-01 -1.680750e-01 4 b_progGeneral 1.273018e+00 0.0809187810 1.148042e+00 1.398220e+00 5 b_progAcademic 8.458137e-01 0.0716282175 7.205499e-01 9.549422e-01 6 lp__ -1.320972e+03 1.6287393824 -1.324051e+03 -1.319034e+03 library(kableExtra) tidy(attendance_brms) %&gt;% filter(grepl(term, pattern = &#39;^b&#39;)) %&gt;% mutate(term = c(&#39;Intercept&#39;, &#39;Math&#39;, &#39;Male&#39;, &#39;General&#39;, &#39;Academic&#39;)) %&gt;% rename_all(str_to_title) %&gt;% kable(digits = 2) Term Estimate Std.error Lower Upper Intercept 1.49 0.08 1.35 1.61 Math -0.01 0.00 -0.01 -0.01 Male -0.25 0.04 -0.33 -0.17 General 1.27 0.08 1.15 1.40 Academic 0.85 0.07 0.72 0.95 tidybayes Bayesian analysis + tidy data + geoms library(tidybayes) attendance %&gt;% add_fitted_draws(attendance_brms) # A tibble: 125,600 x 10 # Groups: id, gender, math, daysabs, prog, .row [314] id gender math daysabs prog .row .chain .iteration .draw .value &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; 1 1001 Male 63 4 Academic 1 NA NA 1 5.05 2 1001 Male 63 4 Academic 1 NA NA 2 5.52 3 1001 Male 63 4 Academic 1 NA NA 3 4.83 4 1001 Male 63 4 Academic 1 NA NA 4 4.97 5 1001 Male 63 4 Academic 1 NA NA 5 5.41 6 1001 Male 63 4 Academic 1 NA NA 6 4.98 7 1001 Male 63 4 Academic 1 NA NA 7 5.37 8 1001 Male 63 4 Academic 1 NA NA 8 5.30 9 1001 Male 63 4 Academic 1 NA NA 9 4.99 10 1001 Male 63 4 Academic 1 NA NA 10 5.20 # ... with 125,590 more rows sleepstudy %&gt;% modelr::data_grid(Days = Days, Subject = levels(Subject)) %&gt;% add_predicted_draws(sleepstudy_brms) %&gt;% ggplot(aes(x = Days)) + stat_lineribbon(aes(y = .prediction), color = NineteenEightyR::electronic_night()[1], .width = seq(.5, .99, by = .01), alpha = .5, show.legend = F) + geom_point(aes(y = Reaction), data = sleepstudy, alpha=.25) + scico::scale_fill_scico_d(alpha=.1, palette = &#39;acton&#39;, direction = -1) Questions about tidybayes may be shouted across the street 😀 Developed by Matthew Kay Assistant Professor at UMSI "],
["model-diagnostics.html", "Model Diagnostics", " Model Diagnostics Numerous model diagnostics are available to the Bayesian analyst The Stan ecosystem makes exploring these not only easy, but fun! "],
["shiny-stan.html", "Shiny stan", " Shiny stan shinystan allows for interactive exploration of model diagnostics Just use launch_shinystan on any model object from rstan, rstanarm, or brms launch_shinystan(attendance_brms) "],
["posterior-predictive-checks.html", "Posterior Predictive Checks", " Posterior Predictive Checks Posterior predictive checks can let us inspect what the model suggests for our target variable vs. what actually is the case pp_check(attendance_brms) The Poisson’s underlying assumption of the mean equaling the variance rarely holds with typical data. One way to handle overdispersion in count models is to move to something like negative binomial or other approaches. Interestingly, for Poisson models we can have a random effect per observation (even in the non-Bayesian context)5 to model additional variance. In this case, our pp_check suggests a much better result. attendance_brms_add_re = update(attendance_brms, . ~ . + (1|id), newdata = attendance) pp_check(attendance_brms_add_re) For more on this see Ben Bolker’s demonstration with lme4. This essentially changes the model to incorporate a Poisson log-normal distribution. As Montesinos-López et al. (2017) describe: &gt; The Poisson component of the Poisson-lognormal distribution accommodates integer inputs (or outputs) to describe the actual number of counts observed within a single unit or sample, while the lognormal component of the distribution describes the overdispersion in the Poisson rate parameter…↩ "],
["observation-level.html", "Observation Level", " Observation Level We can get into observation level diagnostics as well While the process is technical, we can use the simple visualization to note ‘outliers’6 - Think of it as leave-one-out (LOO) cross-validation error for a single data point Look for values above .7 (though this default can be changed) plot(loo(attendance_brms)) title(&#39;&#39;) Pareto smoothed importance sampling. See Vehtari, Gelman, and Gabry (2015) and Vehtari, Gelman, and Gabry (2017) for details.↩ "],
["model-performance.html", "Model Performance ", " Model Performance "],
["prediction.html", "Prediction", " Prediction The usual methods of fitted "],
["model-comparison.html", "Model Comparison", " Model Comparison Model comparison can be achieved in much the same way we do with standard models WAIC = widely applicable information criterion - a Bayesian AIC (lower is better) In the Bayesian context, we would have a distribution for the WAIC also waic(attendance_brms, attendance_brms_add_re) WAIC SE attendance_brms 2669.26 146.95 attendance_brms_add_re 1420.24 26.20 attendance_brms - attendance_brms_add_re 1249.02 135.66 "],
["model-averaging.html", "Model Averaging", " Model Averaging Why choose a model? Average predictions across models via stacking ## pp_average(attendance_brms, attendance_brms_add_re) Estimate Est.Error Q2.5 Q97.5 [1,] 3.9950 2.827536 0 11.000 [2,] 3.8250 2.579925 0 10.000 [3,] 2.7075 2.184921 0 8.000 [4,] 3.6575 2.686678 0 10.025 [5,] 3.5975 2.293173 0 8.025 [6,] 11.9450 4.857568 4 23.000 "],
["summary.html", "Summary", " Summary Implementing Bayesian methods has never been easier rstanarm and brms make allow one to worry about the concepts instead of syntax Bayesian analysis provides more ways to combat complex models, diagnosis issues, get creative with stats "],
["exercise.html", "Exercise", " Exercise Whether a survey respondent agrees or disagrees with a conservative statement about the role of women in society 1974/1975 Survey Women should take care of running their homes and leave running the country up to men Modeled as a function of the gender and education of the respondents data(&quot;womensrole&quot;, package = &quot;HSAUR3&quot;) womensrole_glm &lt;- glm(cbind(agree, disagree) ~ education + gender, data = womensrole, family = binomial) ## summary(womensrole_glm) "],
["references.html", "References", " References Stan discussion group includes forums specific to rstanarm and brms "]
]
